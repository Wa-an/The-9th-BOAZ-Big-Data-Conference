{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "from selenium.webdriver.common.desired_capabilities import  DesiredCapabilities \n",
    "import time \n",
    "from selenium.webdriver.common.keys import Keys \n",
    "import datetime as dt \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:\\\\Users\\\\rladh\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe')\n",
    "\n",
    "\n",
    "startdate=dt.date(year=2018,month=1,day=1) #시작날짜 \n",
    "untildate=dt.date(year=2018,month=1,day=2) # 시작날짜 +1 \n",
    "enddate=dt.date(year=2018,month=11,day=30) # 끝날짜\n",
    "\n",
    "query=\"새우깡\" \n",
    "totaltweets=[] \n",
    "while not enddate==startdate: \n",
    "    url='https://twitter.com/search?q='+query+'%20since%3A'+str(startdate)+'%20until%3A'+str(untildate)+'&amp;amp;amp;amp;amp;amp;lang=eg' \n",
    "    driver.get(url) \n",
    "    html = driver.page_source \n",
    "    soup=BeautifulSoup(html,'html.parser') \n",
    "     \n",
    "    lastHeight = driver.execute_script(\"return document.body.scrollHeight\") \n",
    "    while True: \n",
    "         \n",
    "        dailyfreq={'Date':startdate} \n",
    "\n",
    "        wordfreq=0 \n",
    "        tweets=soup.find_all(\"p\", {\"class\": \"TweetTextSize\"}) \n",
    "                     \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") \n",
    "        time.sleep(1) \n",
    "         \n",
    "        newHeight = driver.execute_script(\"return document.body.scrollHeight\") \n",
    "         \n",
    "\n",
    "        if newHeight != lastHeight: \n",
    "            html = driver.page_source \n",
    "            soup=BeautifulSoup(html,'html.parser') \n",
    "            tweets=soup.find_all(\"p\", {\"class\": \"TweetTextSize\"}) \n",
    "            wordfreq=len(tweets) \n",
    "        else: \n",
    "            dailyfreq['Frequency']=wordfreq \n",
    "            wordfreq=0 \n",
    "            startdate=untildate \n",
    "            untildate+=dt.timedelta(days=1) \n",
    "            dailyfreq={} \n",
    "            totaltweets.append(tweets) \n",
    "            break \n",
    "\n",
    "        lastHeight = newHeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(columns=['id','message'])\n",
    "\n",
    "number=1 \n",
    "for i in range(len(totaltweets)): \n",
    "    for j in range(len(totaltweets[i])): \n",
    "        df = df.append({'id': number,'message':(totaltweets[i][j]).text}, ignore_index=True) \n",
    "        number = number+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('C:\\\\Users\\\\rladh\\\\Downloads/2018년도 새우깡 크롤링.xlsx',sheet_name='Sheet1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
